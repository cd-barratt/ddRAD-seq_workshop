<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Tutorial: denovo_map</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ddRAD-seq_workshop</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="00_setup.html">00 - Setting up the data and scripts for analysis</a>
    </li>
    <li>
      <a href="01_download_data.html">01 - Downloading data from ENA</a>
    </li>
    <li>
      <a href="02_process_radtags.html">02 - Demultiplexing sequencing data (process_radtags)</a>
    </li>
    <li>
      <a href="03_denovo_map.html">03 - Running Stacks 2 (denovo_map)</a>
    </li>
    <li>
      <a href="04_Admixture.html">04 - Population structure (Admixture)</a>
    </li>
    <li>
      <a href="05_sNMF.html">05 - Population structure (sNMF)</a>
    </li>
    <li>
      <a href="06_DAPC.html">06 - Population structure (DAPC)</a>
    </li>
    <li>
      <a href="07_RAxML.html">07 - Phylogenetic relationships (RAxML)</a>
    </li>
    <li>
      <a href="08_F-stats.html">08 - Genetic Diversity (F-stats)</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/cd-barratt/ddRAD-seq_workshop/">GitHub</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Tutorial: denovo_map</h1>

</div>


<p><br />
<br />
</p>
<div id="timings" class="section level3">
<h3>Timings</h3>
<ol style="list-style-type: decimal">
<li>Run denovo_map (~2 hours)</li>
<li>Filtering with VCFtools and populations to assess output file quality (15 min)</li>
</ol>
<p>All steps done in EVE cluster</p>
<p><br />
<br />
</p>
</div>
<div id="objectives" class="section level3">
<h3>Objectives</h3>
<p>This exercise will show you how to run denovo_map in Stacks from start to finish (assuming that you have demultiplexed data after running process_radtags). For this exercise we will use some already processed data for <em>Hyphaene coriacea</em>, a palm species occurring on Madagascar. We’ll then check the quality of the output files using VCFtools and populations to do some further filtering.</p>
<p>Some notes:</p>
<p><br />
</p>
<p>Paper: <a href="https://www.nature.com/articles/nprot.2017.123">Rochette and Catchen 2017</a><strong><em> </em></strong> that paper is a bit out of date, since Stacks 2 came in 2019 with many new ways of dealing with paired-end data (IMPORANT: don’t merge/concatenate the 4 output files from process_radtags!!), otherwise it is really useful.</p>
<p><br />
</p>
<p>All the scripts from the paper can be found [here] (<a href="https://bitbucket.org/rochette/rad-seq-genotyping-demo/src/master/demo_scripts/" class="uri">https://bitbucket.org/rochette/rad-seq-genotyping-demo/src/master/demo_scripts/</a>)</p>
<p><br />
<br />
</p>
</div>
<div id="run-denovo_map" class="section level3">
<h3>1. Run denovo_map</h3>
<div id="parameter-optimization-with-denovo_map.pl" class="section level4">
<h4>Parameter optimization with denovo_map.pl</h4>
<p>After process_radtags you will have 4 files per sample (sample.1.fq, sample.2.fq, sample.rem.1.fq, sample.rem.2.fq) and you can run STACKS step by step, or run the denovo_map.pl wrapper, which does the same in just one line. It’s highly recommended to do parameter optimization before continuing with the rest of final steps:</p>
<p><br />
</p>
<p>Paper: <a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12775">Paris, Stevens, &amp; Catchen, 2017</a></p>
<p><br />
</p>
<p>For the parameter optimization, the <a href="https://catchenlab.life.illinois.edu/stacks/comp/denovo_map.php">denovo_map.pl</a> program is used, running it several times changing the different parameters as recommended (m=3, M=n). The denovo_map.pl will use a test.popmap to know which samples to use for the run. To make a test.popmap choose a random subset of samples from all populations (e.g., 2-3 individuals per pop) and specify that all samples belong to the same pop even if they don’t (just for the optimization).</p>
<p><br />
</p>
<p>This script is going to run denovo_map.pl 9 times (M=n=1-9), and create an output with subsequent folders (stacks.$M)</p>
<pre class="r"><code>
#!/bin/bash
#SBATCH -J denovo_map_test.parameters
#SBATCH --mail-user=YOUREMAIL@gmail.com
#SBATCH --mail-type=BEGIN,END,FAIL,TIME_LIMIT
#SBATCH --output=/work/$USER/%x-%j.out
#SBATCH --error=/work/$USER/%x-%j.err 
#SBATCH --cpus-per-task=20 
#SBATCH --mem-per-cpu=8G
#SBATCH -t 48:00:00

# Set the requested number of cores to the number of Threads your app should use
export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK:-1}

# Paths and filenames for this analysis

M_values=&quot;1 2 3 4 5 6 7 8 9&quot;
WORK_DIR=&quot;/work/$USER/ddRAD-seq_workshop&quot;
popmap=&quot;/work/$USER/ddRAD-seq_workshop/data/Excercise_3/popmaps/test.popmap.txt&quot;
OUT_DIR=&quot;/work/$USER/ddRAD-seq_workshop/output/Excercise_3/test.denovo&quot;

#Create OUT_DIR and subdirectories

cd &quot;$WORK_DIR&quot; || exit 
mkdir &quot;$OUT_DIR&quot;
cd &quot;$OUT_DIR&quot; || exit 

for M in $M_values
do
    mkdir stacks.M&quot;$M&quot;
done


## Load modules and activate software

module purge
module load Anaconda3
source activate /global/apps/stacks_2.61/


# denovo_map.pl - it will execute the Stacks pipeline by running each of the Stacks components #individually: ustacks, cstacks, sstacks, tsv2bam, gstacks and populations. 
# We are doing this to select the parameters M (ustacks) and n (cstacks) which optimal value depends #on the amount of genetic diversity within the species and on the quality of the raw data as well. 
# This is done with only a subset of samples from all the populations. This subset is written in the #test.popmap files and therefore Stacks will only run the analyses over those samples specified. We will #vary M and n (M=n) from 1 to 9, and set m = 3.   

# -samples = file path to the samples (samples will be read from population map)
# --popmap = file path to the population map (&lt;sample name&gt;&lt;TAB&gt;&lt;population&gt;)
# -o = file path to write the pipeline output files
# -X = additional options for specific pipeline components, e.g. -X &quot;populations: --min-maf 0.05&quot;. We will #run populations separately afterwards
# -M = number of mismatches allowed between stacks within individuals (for ustacks)
# -n =number of mismatches allowed between stacks between individuals (for cstacks)
# -m = Minimum depth of coverage required to create a stack (default 3)
# --paired = after assembling RAD loci, assemble contigs for each locus from paired-end reads
# --rm-pcr-duplicates = remove all but one set of read pairs of the same sample that have the same #insert length
# -r = minimum percentage of individuals in a population required to process a locus for that population #(for populations; default: 0)
# -T = the number of threads/CPUs to use (default: 1)

# Run denovo_map on the subset of samples set by the test.popmap

for M in $M_values 
do
    out_dir=&quot;$OUT_DIR/stacks.M$M&quot;
    reads_dir=&quot;$WORK_DIR/data/Excercise_3/demultiplexed_data/HC&quot;
        log_file=&quot;$out_dir&quot;/denovo_map.oe
denovo_map.pl --samples &quot;$reads_dir&quot; --popmap &quot;$popmap&quot; -o &quot;$out_dir&quot; -T &quot;$SLURM_CPUS_PER_TASK&quot; -M &quot;$M&quot; -n &quot;$M&quot; -m 3 --paired &amp;&gt; &quot;$log_file&quot;
done

# Run populations again with &#39;-r 0.80&#39; (loci present in 80% of samples)

for M in $M_values 
do
    stacks_dir=stacks.M&quot;$M&quot;
    out_dir=&quot;$stacks_dir&quot;/populations.r80
    mkdir &quot;$out_dir&quot;
    log_file=&quot;$out_dir&quot;/populations.oe
    populations -P &quot;$stacks_dir&quot; -O &quot;$out_dir&quot; -t &quot;$SLURM_CPUS_PER_TASK&quot; -r 0.80 &amp;&gt; &quot;$log_file&quot;
done
</code></pre>
<p><br />
</p>
<p>In each folder stacks.$M we will have all the output from STACKS and another folder, populations.r80 with the results from running populations showing only the number of polymorphic loci shared across 80% of the samples (the r80 loci). From these runs we need to extract some important information to be able to choose the best value of M=n for our data.</p>
<pre class="r"><code>#!/bin/bash
#SBATCH -J extract_results
#SBATCH --mail-user=YOUREMAIL@gmail.com
#SBATCH --mail-type=BEGIN,END,FAIL,TIME_LIMIT
#SBATCH --output=/work/$USER/%x-%j.out
#SBATCH --error=/work/$USER/%x-%j.err 
#SBATCH --cpus-per-task=2 
#SBATCH --mem-per-cpu=3G
#SBATCH -t 1:00:00

# Paths and filenames for this analysis

M_values=&quot;1 2 3 4 5 6 7 8 9&quot;
WORK_DIR=&quot;/work/$USER/ddRAD-seq_workshop/output/Excercise_3/test.denovo&quot;

## Load modules and activate software

module purge
module load Anaconda3
source activate /global/apps/stacks_2.61

cd &quot;$WORK_DIR&quot; || exit 
mkdir &quot;$WORK_DIR/results&quot;


for M in $M_values
do
stacks-dist-extract stacks.M&quot;$M&quot;/populations.r80/populations.log.distribs snps_per_loc_postfilters &gt;&gt; results/M&quot;$M&quot;_snp_distribution.tsv
cat stacks.M&quot;$M&quot;/populations.r80/populations.sumstats.tsv | grep -v &quot;^#&quot; | cut -f 1 | sort -n | uniq | wc -l &gt;&gt; results/M&quot;$M&quot;_r80.polymorphicLOCI.tsv
awk &#39;NR == 6 {print $5}&#39; stacks.M&quot;$M&quot;/populations.r80/populations.sumstats_summary.tsv &gt;&gt; results/M&quot;$M&quot;_r80.polymorphicLOCI_summary.tsv
cat results/*.polymorphicLOCI.tsv &gt;&gt; results/all.polymorphicLOCI.tsv
cat  results/*.polymorphicLOCI_summary.tsv &gt; results/all.polymorphicLOCI_summary.tsv
done
</code></pre>
<p><br />
</p>
<p>Then, in the /results folder you will be able to find: - Total number of assembled loci: count the number of lines in the populations.haplotypes.tsv file. - Number of polymorphic r80 loci is in the populations.sumstats_summary.tsv file. - the SNPs-per-locus after filtering distributions in the populations.log.distribs. This is possible with the “stacks-dist-extract” utility from Stacks (this step in included in the script). To know which M=n to use, plot the polymorphic loci r80 per each parameter setting and the new polymorphic loci found while increasing M:</p>
<p><br />
</p>
<p>[SHOW FIGURES]</p>
<p><br />
</p>
<p>When the number of polymorphic loci does not get significantly higher by making M=n higher, then that’s the M=n we choose. In this case it would be M=4</p>
<p><br />
</p>
</div>
<div id="run-denovo_map.pl" class="section level4">
<h4>Run denovo_map.pl</h4>
<p>Now that we have optimized the parameters we can run denovo_map.pl program with the chosen M. Here you could decide to make m (depth coverage) higher, although than can also be filtered later with VCFtoolsFIGURES</p>
<pre class="r"><code>#!/bin/bash
#SBATCH -J denovo_map_full
#SBATCH --mail-user=YOUREMAIL@gmail.com
#SBATCH --mail-type=BEGIN,END,FAIL,TIME_LIMIT
#SBATCH --output=/work/mendez/%x-%j.out
#SBATCH --error=/work/mendez/%x-%j.err 
#SBATCH --cpus-per-task=14 
#SBATCH --mem-per-cpu=8G
#SBATCH -t 48:00:00

# Set the requested number of cores to the number of Threads your app should use
export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK:-1}

# Paths and filenames for this analysis

M=SETYOURM
WORK_DIR=&quot;/work/$USER/ddRAD-seq_workshop&quot;
popmap=&quot;/work/$USER/ddRAD-seq_workshop/data/Excercise_3/popmaps/popmap.txt&quot;

out_dir=&quot;/$WORK_DIR/output/Excercise_3/stacks.denovo&quot;
reads_dir=&quot;$WORK_DIR/data/Excercise_3/demultiplexed_data/HC&quot;
log_file=&quot;$out_dir&quot;/denovo_map.oe

cd &quot;$WORK_DIR&quot; || exit 
mkdir &quot;$out_dir&quot;

## Load modules and activate software

module purge
module load Anaconda3
source activate /global/apps/stacks_2.61

# denovo_map.pl - it will execute the Stacks pipeline by running each of the Stacks components individually: ustacks, cstacks, sstacks, tsv2bam, gstacks and populations. 
# We are doing this to select the parameters M (ustacks) and n (cstacks) which optimal value depends on the amount of genetic diversity within the species and with the quality of the raw data as well. 
# Therefore this has to be done with every species separately, with only a subset of samples from all the populations. This subset is written in the test.popmap files and therefore Stacks will only 
# run the analyses over those samples specified. We will vary M and n (M=n) from 1 to 9, and set m = 3.   

# -samples = file path to the samples (samples will be read from population map)
# --popmap = file path to the population map (&lt;sample name&gt;&lt;TAB&gt;&lt;population&gt;)
# -o = file path to write the pipeline output files
# -X = additional options for specific pipeline components, e.g. -X &quot;populations: --min-maf 0.05&quot;. We will #run populations separately afterwards
# -M = number of mismatches allowed between stacks within individuals (for ustacks)
# -n =number of mismatches allowed between stacks between individuals (for cstacks)
# -m = Minimum depth of coverage required to create a stack (default 3)
# --paired = after assembling RAD loci, assemble contigs for each locus from paired-end reads
# --rm-pcr-duplicates = remove all but one set of read pairs of the same sample that have the same #insert length
# -r = minimum percentage of individuals in a population required to process a locus for that population #(for populations; default: 0)
# -T = the number of threads/CPUs to use (default: 1)


# Run denovo_map on the subset of samples told by the popmap

denovo_map.pl --samples &quot;$reads_dir&quot; --popmap &quot;$popmap&quot; -o &quot;$out_dir&quot; -T &quot;$SLURM_CPUS_PER_TASK&quot; -M &quot;$M&quot; -n &quot;$M&quot; -m 3 --paired -X &quot;populations: --vcf&quot; &amp;&gt; &quot;$log_file&quot;</code></pre>
<p><br />
<br />
</p>
</div>
</div>
<div id="filtering-with-vcftools-and-populations-to-assess-output-file-quality" class="section level3">
<h3>2. Filtering with VCFtools and populations to assess output file quality</h3>
<p>populations - There are four primary filters that should be used, particularly in de novo analyses, to control for false-positive loci. They control (i) the fraction of individuals of a single population a locus must be found in to be processed (-r), (ii) the number of populations that a locus must be found in to be processed (-p), (iii) the minimum allele frequencies a variable site must possess to be included (–min_maf), and (iv) the maximum level of heterozygosity a variable site can possess to be included (–max_obs_het). The -r and -p filters primarily provide biological control (e.g., a population genetic analysis (widely available loci) versus a phylogenetic study (maximum loci across any subset of species)). Most widely used parameters for population genetic studies are:</p>
<ul>
<li>r=0.80<br />
</li>
<li>min-maf=0.05<br />
</li>
<li>max-obs-het=0.70<br />
</li>
</ul>
<p><br />
</p>
<div id="filtering-with-vcftools" class="section level4">
<h4>Filtering with VCFtools</h4>
<pre class="r"><code>#!/bin/bash

#SBATCH -J vcftools_filtering
#SBATCH --mail-user=YOUREMAIL@gmail.com
#SBATCH --mail-type=BEGIN,END,FAIL,TIME_LIMIT
#SBATCH --chdir /work/YOURUSER    
#SBATCH --output=/work/$USER/%x-%j.out
#SBATCH --error=/work/$USER/%x-%j.err  
#SBATCH --mem-per-cpu=4G
#SBATCH -t 48:00:00
# Paths and filenames for this analysis

WORK_DIR=&quot;/work/$USER/ddRAD-seq_workshop&quot;

out_dir=&quot;/work/$USER/ddRAD-seq_workshop/output/Excercise_3/stacks.denovo/VCFtools&quot;
vcf_dir=&quot;$WORK_DIR/stacks.denovo/populations.snps.vcf&quot;
log_file=&quot;$out_dir&quot;/vcf_filtering_m5-100_miss0.25_2alleles.oe
    
## Load modules and activate software

module load foss/2019b VCFtools/0.1.16

# VCFtools - vcftools is a suite of functions for use on genetic variation data in the form of VCF and BCF files. 
#The tools provided will be used mainly to summarize data, run calculations on data, filter out data, and convert data into other useful file formats.
# SYNOPSIS:
# vcftools [ --vcf FILE | --gzvcf FILE | --bcf FILE] [ --out OUTPUT PREFIX ] [ FILTERING OPTIONS ] [ OUTPUT OPTIONS ]

# Run VCFtools to calculate some basic stats from out vcf files per species 

cd &quot;$out_dir&quot; 
vcftools --vcf &quot;$vcf_dir&quot; --remove-indels --max-missing 0.50 --min-alleles 2 --max-alleles 2 --min-meanDP 5 --max-meanDP 100 --minDP 5 --maxDP 100 --recode --out &quot;./m5-100_miss0.50_2alleles_&quot; &amp;&gt; &quot;$log_file&quot; </code></pre>
<p><br />
</p>
<p>VCFtools – If you want to know more, you can check this tutorial: <a href="https://speciationgenomics.github.io/filtering_vcfs/" class="uri">https://speciationgenomics.github.io/filtering_vcfs/</a> With VCFtools you can get (<a href="https://vcftools.github.io/man_latest.html" class="uri">https://vcftools.github.io/man_latest.html</a>): –freq2 = allele frequency –depth = mean depth per individual –site-mean-depth = mean depth per site –missing-indv = proportion of missing data per individual –missing-site = proportion of missing data per site –het = heterozygosity and inbreeding coefficient per individual</p>
<pre class="r"><code>#!/bin/bash

#SBATCH -J vcftools
#SBATCH --mail-user=YOUREMAIL@gmail.com
#SBATCH --mail-type=BEGIN,END,FAIL,TIME_LIMIT
#SBATCH --chdir /work/YOURUSER  
#SBATCH --output=/work/mendez/%x-%j.out
#SBATCH --error=/work/mendez/%x-%j.err  
#SBATCH --mem-per-cpu=4G
#SBATCH -t 48:00:00

# Paths and filenames for this analysis

WORK_DIR=&quot;/work/$USER/ddRAD-seq_workshop&quot;
out_dir=&quot;/work/$USER/ddRAD-seq_workshop/output/Excercise_3/stacks.denovo/VCFtools&quot;
mkdir &quot;$out_dir&quot;
vcf_dir=&quot;$WORK_DIR/stacks.denovo/VCFtools/ m5-100_miss0.50_2alleles_.vcf&quot;
log_file=&quot;$out_dir&quot;/vcftools.oe

## Load modules and activate software

module load foss/2019b VCFtools/0.1.16

# VCFtools - vcftools is a suite of functions for use on genetic variation data in the form of VCF and BCF #files. 
#The tools provided will be used mainly to summarize data, run calculations on data, filter out data, and #convert data into other useful file formats.
# SYNOPSIS:
# vcftools [ --vcf FILE | --gzvcf FILE | --bcf FILE] [ --out OUTPUT PREFIX ] [ FILTERING OPTIONS ] [ OUTPUT OPTIONS ]

# Run VCFtools to calculate some basic stats from out vcf files

cd &quot;$out_dir&quot; 
    vcftools --vcf &quot;$vcf_dir&quot; --freq2 --out &quot;./freq2&quot; --max-alleles 2 &amp;&gt; &quot;$log_file&quot;
    vcftools --vcf &quot;$vcf_dir&quot; --depth --out &quot;./ind_depth&quot; &amp;&gt; &quot;$log_file&quot; 
    vcftools --vcf &quot;$vcf_dir&quot; --site-mean-depth --out &quot;./mean_depth_site&quot; &amp;&gt; &quot;$log_file&quot;
    vcftools --vcf &quot;$vcf_dir&quot; --site-quality --out &quot;./site_quality&quot; &amp;&gt; &quot;$log_file&quot;
    vcftools --vcf &quot;$vcf_dir&quot; --missing-indv --out &quot;./missing_ind&quot; &amp;&gt; &quot;$log_file&quot;
    vcftools --vcf &quot;$vcf_dir&quot; --missing-site --out &quot;./missing_ind&quot; &amp;&gt; &quot;$log_file&quot;
    vcftools --vcf &quot;$vcf_dir&quot; --het --out &quot;./het&quot; &amp;&gt; &quot;$log_file&quot;    </code></pre>
<p><br />
</p>
<p>The most important file at this point is the .imiss file which contains the percentage of missing data per individual. It has been shown that deleting individuals with high percentage of missing data can help recovering higher number of loci.</p>
<p><br />
</p>
<p>Paper: [Cerca et al. 2021] (<a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13562" class="uri">https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13562</a>)</p>
<p><br />
</p>
<p>Check the .imiss file, identify individuals with high missing data and create a new popmap (e.g., popmap_75, if you have deleted every individual with more than 75% of missing data) and run populations again with this new popmap and further filter the data to get our final dataset.</p>
<p><br />
</p>
</div>
<div id="filtering-with-populations" class="section level4">
<h4>Filtering with populations</h4>
<pre class="r"><code>#!/bin/bash

#SBATCH -J populations
#SBATCH --mail-user=YOUREMAIL@gmail.com
#SBATCH --mail-type=BEGIN,END,FAIL,TIME_LIMIT
#SBATCH --output=/work/mendez/%x-%j.out
#SBATCH --error=/work/mendez/%x-%j.err 
#SBATCH --cpus-per-task=4 
#SBATCH --mem-per-cpu=6G
#SBATCH -t 48:00:00

# Set the requested number of cores to the number of Threads your app should use
export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK:-1}

# Paths and filenames for this analysis
 
WORK_DIR=&quot;/work/$USER/ddRAD-seq_workshop&quot;

out_dir=&quot;/work/$USER/ddRAD-seq_workshop/output/Excercise_3/stacks.denovo/populations/populations.singleSNP.r075.m5.maf005.het07&quot;
mkdir &quot;$out_dir&quot;
vcf_dir=&quot;$WORK_DIR/stacks.denovo/VCFtools/filtered.m5-100_miss0.50_2alleles_.vcf&quot;
popmap=&quot;/work/$USER/ddRAD-seq_workshop/data/Excercise_3/popmaps/popmap_90.txt&quot;
log_file=&quot;$out_dir&quot;/populations.oe

## Load modules and activate software

module purge
module load Anaconda3
source activate /global/apps/stacks_2.61

# populations - it will analyze a population of individual samples computing a number of population genetics statistics 
# as well as exporting a variety of standard output formats. A population map specifying which individuals belong to which 
# population is submitted to the program and the program will then calculate population genetics statistics such as expected/observed 
# heterozygosity, π, and FIS at each nucleotide position. The populations program will compare all populations pairwise to compute FST.  
# The populations program provides strong filtering options to only include loci or variant sites that occur at certain frequencies in  
# each population or in the metapopulation.

# -P = path to the directory containing the Stacks files (the gstacks output).
# --popmap = file path to the population map (&lt;sample name&gt;&lt;TAB&gt;&lt;population&gt;)
# -O = file path to write the pipeline output files
# -p = minimum number of populations a locus must be present in to process a locus.
# -m = coverage threshold
# -r = minimum percentage of individuals in a population required to process a locus for that population.
# --min-maf = specify a minimum minor allele frequency required to process a nucleotide site at a locus (0 &lt; min_maf &lt; 0.5).
# --write-single-snp = restrict data analysis to only the first SNP per locus.
# --write-random-snp = restrict data analysis to one random SNP per locus.
# --fstats — enable SNP and haplotype-based F statistics.
# -T = the number of threads/CPUs to use (default: 1)

# Run populations with &quot;-r 0.75&quot; (loci present in 75% of samples), min-maf 0.05 (a variable site must possess a minimum allele frequency of 5% to be included) 
# --max-obs-het 0.7 (maximum level of heterozygosity a variable site can possess to be included) and writing only one single SNP (--write-single-snp).

populations -V &quot;$vcf_dir&quot; -O &quot;$out_dir&quot; --popmap &quot;$popmap&quot; \
-t &quot;$SLURM_CPUS_PER_TASK&quot; -r 0.75 --min-maf 0.05 --max-obs-het 0.7 --write-single-snp --fstats --hwe --vcf --plink --phylip --phylip-var --phylip-var-all &amp;&gt; &quot;$log_file&quot;
</code></pre>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
